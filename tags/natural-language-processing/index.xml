<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Natural Language Processing on</title><link>https://nathanrooy.github.io/tags/natural-language-processing/</link><description>Recent content in Natural Language Processing on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 22 Mar 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://nathanrooy.github.io/tags/natural-language-processing/index.xml" rel="self" type="application/rss+xml"/><item><title>Word2vec from Scratch with Python and NumPy</title><link>https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/</link><pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate><guid>https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/</guid><description>Introduction Since joining a tech startup back in 2016, my life has revolved around machine learning and natural language processing (NLP). Trying to extract faint signals from terabytes of streaming social media is the name of the game. Because of this, I&amp;rsquo;m constantly experimenting and implementing different NLP schemes; word2vec being among the simplest and coincidently yielding great predictive value. The underpinnings of word2vec are exceptionally simple and the math is borderline elegant.</description></item></channel></rss>